#!/usr/bin/env python

"""
This is the script to genearte the tercile plot based on the 
forecast(hindcast) that is generated by Andrew Ross at GFDL.

"""
from typing import (
    Literal,
    List,
    Union
)
import os
import glob
import warnings
from datetime import date
import requests
from dateutil.relativedelta import relativedelta
from bs4 import BeautifulSoup
import cftime
import numpy as np
import pandas as pd
import xarray as xr
from scipy.stats import norm as normal
from mom6 import DATA_PATH
from mom6.mom6_module.mom6_types import RegionalOptions,ModelGridTypeOptions,ModelExperimentTypeOptions,DataSourceOptions

warnings.simplefilter("ignore")
xr.set_options(keep_attrs=True)


class OpenDapStore:
    """class to handle the OPeNDAP request
    """
    def __init__(
            self,
            grid : ModelGridTypeOptions = 'raw',
            data_type : ModelExperimentTypeOptions = 'historical'
    ) -> None:
        """
        input for the class to get the opendap data

        Parameters
        ----------
        grid : Literal[&#39;raw&#39;,&#39;regrid&#39;], optional
            The data extracted should be the regridded result or 
            the original model grid (curvilinear), by default 'raw'
        data_type : Literal[&#39;forecast&#39;,&#39;historical&#39;], optional
            This determine the data type the user want to use 
            to calculate the indexes, by default 'historical'

        """
        self.grid = grid
        self.data_type = data_type


    def get_catalog(self)-> list:
        """Getting the cataloged files

        Returns
        -------
        list
            a list of url in the form of string that 
            provide the locations of the data when
            accessing using opendap

        Raises
        ------
        FileNotFoundError
            When the files is empty that means the init setting 
            or code must have some incorrect pairing. Debug possibly 
            needed.
        """
        # print(self.data_type)
        if self.data_type == 'historical' :
            datatype = 'hist_run'
        elif self.data_type == 'forecast' :
            datatype = 'hindcast'
        # print(datatype)

        if self.grid == 'raw' :
            gridtype = ''
        elif self.grid == 'regrid' :
            gridtype = 'regrid'

        catalog_url = (
            'https://psl.noaa.gov/thredds/catalog/'+
            f'Projects/CEFI/regional_mom6/{datatype}/{gridtype}/'
        )
        opendap_url = (
            'https://psl.noaa.gov/thredds/dodsC/'+
            f'Projects/CEFI/regional_mom6/{datatype}/{gridtype}/'
        )

        # Send a GET request to the URL
        html_response = requests.get(catalog_url+'catalog.html', timeout=10)

        # Parse the html response
        soup = BeautifulSoup(html_response.text, 'html.parser')

        # get all code tage in a tag in the "content" div
        div_content = soup.find('div', class_='content')
        a_tags = div_content.find_all('a')
        all_file_list = [a_tag.find_all('code')[0].text for a_tag in a_tags]

        # remove regrid file and directory
        files = []
        for file in all_file_list:
            if 'bilinear' not in file:
                if '.nc' in file:
                    files.append(opendap_url+file)
        if not files :
            raise FileNotFoundError

        return files


class MOM6Forecast:
    """
    Class for various mom6 forecast related calculation
    - get the mom6 files
    - get the mom6 tercile from hindcast 
    - calculate the forecast probability in each tercile
    - get forecast time stamp
    ...
    """
    def __init__(
        self,
        iyear : int,
        imonth : int,
        var : str,
        grid : ModelGridTypeOptions = 'raw',
        source : DataSourceOptions = 'local'
    ) -> None:
        """
        input for the class to get the individual forecast

        Parameters
        ----------
        iyear : int
            initial year of forecast
        imonth : int
            initial month
        var : str
            variable name one want to exetract from the data
        grid : Literal[&#39;raw&#39;,&#39;regrid&#39;], optional
            The data extracted should be the regridded result or 
            the original model grid (curvilinear), by default 'raw'
        source : Literal[&#39;local&#39;,&#39;opendap&#39;], optional
            The source where to import the data, by default 'local'

        """
        self.var = var
        self.iyear = iyear
        self.imonth = imonth
        self.grid = grid
        self.source = source

    def get_mom6(self) -> xr.Dataset:
        """
        Return the mom6 rawgrid/regridded hindcast/forecast field
        with the static field combined and setting the
        lon lat related variables to coordinate 

        Returns
        -------
        xr.Dataset
            The Xarray Dataset object is the merged dataset of
            all forecast field include in the `file_list`. The
            Dataset object is lazily-loaded.
        """
        if self.grid == 'raw' :
            if self.source == 'local':
                # getting the forecast/hindcast data
                mom6_dir = os.path.join(DATA_PATH,"hindcast/")
                file_list = MOM6Misc.mom6_hindcast(mom6_dir)
                # static field
                ds_static = MOM6Static.get_mom6_grid()
            elif self.source == 'opendap':
                file_list = OpenDapStore(grid=self.grid,data_type='forecast').get_catalog()
                for file in file_list:
                    var_flag = 'static' in file
                    if var_flag :
                        ds_static = xr.open_dataset(file)

            # get individual file
            for file in file_list:
                #iyear_flag = f'i{self.iyear}' in file
                imon_flag = f'i{self.imonth}' in file
                var_flag = self.var in file
                if imon_flag and var_flag :
                    ds = xr.open_dataset(file).sel(init=f'{self.iyear}-{self.imonth}').compute()

            # merge the static field with the variables
            ds = xr.merge([ds_static,ds])

        elif self.grid == 'regrid':
            if self.source == 'local':
                # getting the forecast/hindcast data
                mom6_dir = os.path.join(DATA_PATH,"hindcast/regrid/")
                file_list = MOM6Misc.mom6_hindcast(mom6_dir)
            elif self.source == 'opendap':
                file_list = OpenDapStore(grid=self.grid,data_type='forecast').get_catalog()

            # read only the needed file
            for file in file_list:
                #iyear_flag = f'i{self.iyear}' in file
                imon_flag = f'i{self.imonth}' in file
                var_flag = self.var in file
                if imon_flag and var_flag :
                    ds = xr.open_dataset(file).sel(init=f'{self.iyear}-{self.imonth}').compute()

        return ds

    @staticmethod
    def get_mom6_all(
        var : str,
        grid : ModelGridTypeOptions = 'raw',
        source : DataSourceOptions = 'local'
    ) -> xr.Dataset:
        """
        Return the mom6 all rawgrid/regridded hindcast/forecast field
        with the static field combined and setting the
        lon lat related variables to coordinate 

        Parameters
        ----------
        var : str
            variable name one want to exetract from the data
        grid : Literal[&#39;raw&#39;,&#39;regrid&#39;], optional
            The data extracted should be the regridded result or 
            the original model grid (curvilinear), by default 'raw'
        source : Literal[&#39;local&#39;,&#39;opendap&#39;], optional
            The source where to import the data, by default 'local'

        Returns
        -------
        xr.Dataset
            The Xarray Dataset object is the merged dataset of
            all forecast field include in the `file_list`. The
            Dataset object is lazily-loaded.
        """
        if grid == 'raw' :
            if source == 'local':
                # getting the forecast/hindcast data
                mom6_dir = os.path.join(DATA_PATH,"hindcast/")
                file_list = MOM6Misc.mom6_hindcast(mom6_dir)
                # static field
                ds_static = MOM6Static.get_mom6_grid()
            elif source == 'opendap':
                file_list = OpenDapStore(grid=grid,data_type='forecast').get_catalog()
                for file in file_list:
                    var_flag = 'static' in file
                    if var_flag :
                        ds_static = xr.open_dataset(file)

            file_read = [file for file in file_list if var in file]

            # merge the static field with the variables
            ds = xr.open_mfdataset(
                file_read,
                combine='nested',
                concat_dim='init',
                chunks={'init': 4,'member':1,'lead':-1}
            ).sortby('init')
            ds = xr.merge([ds_static,ds])
            ds = ds.isel(init=slice(1,None))  # exclude the 1980 empty field due to merge

        elif grid == 'regrid':
            if source == 'local':
                # getting the forecast/hindcast data
                mom6_dir = os.path.join(DATA_PATH,"hindcast/regrid/")
                file_list = MOM6Misc.mom6_hindcast(mom6_dir)
            elif source == 'opendap':
                file_list = OpenDapStore(grid=grid,data_type='forecast').get_catalog()

            file_read = [file for file in file_list if var in file]
            ds = xr.open_mfdataset(
                file_read,combine='nested',
                concat_dim='init',
                chunks={'init': 1,'member':1,'lead':1}
            ).sortby('init')

        return ds

    def get_mom6_tercile(self) -> xr.Dataset:
        """return the mom6 quantile from the forecast

        Returns
        -------
        xr.Dataset
            A dataset that include the f_lowmid and f_midhigh value which 
            represent SST values at the boundaries between the terciles. 
            `f_lowmid` represent the boundary value between lower and middle
            tercile. `f_midhigh` represent the boundary value between middle
            and upper tercile. (the filename 'quantile' MIGHT be error naming)
        """
        if self.grid == 'raw':
            # getting the forecast/hindcast tercile data
            mom6_dir = os.path.join(DATA_PATH,"tercile_calculation/")
            return xr.open_dataset(f'{mom6_dir}/forecast_quantiles_i{self.imonth:02d}.nc')

        elif self.grid == 'regrid':
            # getting the regridd forecast/hindcast tercile data
            mom6_dir = os.path.join(DATA_PATH,"tercile_calculation/regrid/")
            return xr.open_dataset(f'{mom6_dir}/{self.var}_forecasts_i{self.imonth}.nc')

    def get_mom6_tercile_regional(self) -> xr.Dataset:
        """return the area averaged mom6 tercile value from the forecast/hindcast

        Returns
        -------
        xr.Dataset
            A dataset that include the f_lowmid and f_midhigh value which 
            represent SST values at the boundaries between the terciles. 
            `f_lowmid` represent the boundary value between lower and middle
            tercile. `f_midhigh` represent the boundary value between middle
            and upper tercile. (the filename 'quantile' MIGHT be error naming)
        """

        # getting the regional averaged forecast/hindcast tercile data based always on raw data
        mom6_dir = os.path.join(DATA_PATH,"tercile_calculation/")
        return xr.open_dataset(f'{mom6_dir}/{self.var}_forecasts_i{self.imonth:02d}.region.nc')


    def get_init_fcst_time(
        self,
        lead_bins : List[int] = None
    ) -> dict:
        """Setup the initial and forecast time format for output

        Parameters
        ----------
        lead_bins : List[int]
            The `lead_bin` used to binned the leading month result
            example is `lead_bins = [0, 3, 6, 9, 12]` for four seasonal
            mean.

        Returns
        -------
        dict
            with two key-value pairs, 'init': initial_time and
            'fcst': mean forecasted during the binned period 
        """
        if lead_bins is None:
            lead_bins = [0, 3, 6, 9, 12]

        # get the cftime of initial time
        btime = cftime.datetime(self.iyear,self.imonth,1)

        # store the forecast time format based on all leadtime
        forecasttime = []
        period_length = lead_bins[1]-lead_bins[0]-1  # assuming the bins are equal space
        for l in range(0,12):
            # leadtime period start
            sdate = (
                date.fromisoformat(f'{btime.year}-'+
                                    f'{btime.month:02d}-'+
                                    f'{1:02d}')
                +relativedelta(months=l)
            )
            # leadtime period end
            fdate = (
                date.fromisoformat(f'{btime.year}-'+
                                    f'{btime.month:02d}-'+
                                    f'{1:02d}')
                +relativedelta(months=l+period_length)
            )
            # store array of forecast 3 month period
            forecasttime.append(f'{sdate.strftime("%b")}-{fdate.strftime("%b %Y")}')

        # construct forecast period only during the binned period
        mean_forecasttime = [forecasttime[idx] for idx in lead_bins[:-1]]

        # get the initial time
        ini_time_date = (
            date.fromisoformat(
                f'{btime.year}-'+
                f'{btime.month:02d}-'+
                f'{1:02d}'
            )
        )
        # construct the initial time format
        ini_time = f'{ini_time_date.strftime("%b %Y")}'

        return {'init':ini_time,'fcsts':mean_forecasttime}

    def calculate_tercile_prob(
        self,
        lead_bins : List[int] = None,
        lead_bin : Union[int, float] = None,
        lon : Union[int, float] = None,
        lat : Union[int, float] = None
    ) -> xr.Dataset:
        """
        use single initialization's normal distribution
        and pre-defined tercile value based on the long-term 
        statistic tercile value to find the probability of
        upper ,normal , and lower tercile
        
        It also find the largest probability in upper (positive),
        normal (0), lower (negative)

        Parameters
        ----------
        lead_bins : List[int]
            The `lead_bin` used to binned the leading month result
            ex: one can set `lead_bins = [0, 3, 6, 9, 12]` for four seasonal
            mean. Default is no binning, lead_bins = None.
        
        Returns
        -------
        xr.Dataset
            two variables are in the dataset. (1) tercile_prob 
            (2) tercile_prob_max. 

            1 is a 4D matrix with the dimension 
            of lon x lat x lead x 3. This are the probability of
            upper(lon x lat x lead), normal(lon x lat x lead),
            and lower tercile(lon x lat x lead)

            2 is the 3D matrix of largest probability in upper (positive),
            normal (0), lower (negative) with dimension of (lon x lat x lead)
        """

        # loaded the mom6 raw field
        ds_data = self.get_mom6()

        # load variable to memory
        da_data = ds_data[self.var].isel(init=0)

        if lead_bins is None:
            # average the forecast over the lead bins
            da_binned = da_data.rename({'lead': 'lead_bin'})
        else:
            # setup lead bins to average during forecast lead time
            # (should match lead bins used for the historical data
            # that created the /Datasets.private/regional_mom6/
            # tercile_calculation/historical_terciles.nc
            # [0, 3, 6, 9, 12] produces 3-month averages
            lead_bin_label = np.arange(0,len(lead_bins)-1)

            # average the forecast over the lead bins
            da_binned = (
                da_data
                .groupby_bins('lead', lead_bins, labels=lead_bin_label, right=True)
                .mean('lead')
                .rename({'lead_bins': 'lead_bin'})
            )

        if lead_bin is not None:
            da_binned = da_binned.sel(lead_bin=lead_bin,method='nearest')
        if lon is not None:
            da_binned = da_binned.sel(lon=lon,method='nearest')
        if lat is not None:
            da_binned = da_binned.sel(lat=lat,method='nearest')

        # find a normal distribution for each grid cell and lead bin
        # from the ensemble mean and standard deviation
        #  this is based on 1 initialization
        da_mean = da_binned.mean('member')
        da_std = da_binned.std('member')
        da_dist = normal(loc=da_mean, scale=da_std)

        # load the predetermined hindcast/forecast tercile value
        #  this is based on 30 years statistic 1993-2023
        ds_tercile = self.get_mom6_tercile()

        if lead_bins is None:
            ds_tercile_binned = ds_tercile.rename({'lead': 'lead_bin'})
        else:
            # average the forecast over the lead bins
            ds_tercile_binned = (
                ds_tercile
                .groupby_bins('lead', lead_bins, labels=lead_bin_label, right=True)
                .mean('lead')
                .rename({'lead_bins': 'lead_bin'})
            )

        if lead_bin is not None:
            ds_tercile_binned = ds_tercile_binned.sel(lead_bin=lead_bin,method='nearest')
        if lon is not None:
            ds_tercile_binned = ds_tercile_binned.sel(lon=lon,method='nearest')
        if lat is not None:
            ds_tercile_binned = ds_tercile_binned.sel(lat=lat,method='nearest')

        # use single initialization's normal distribution
        # and pre-defined tercile value to find the
        # probability based on the single initialization
        # that correspond to the long-term statistic tercile value

        #---probability of lower tercile tail
        da_low_tercile_prob = xr.DataArray(
            da_dist.cdf(ds_tercile_binned['f_lowmid']),
            dims=da_mean.dims,
            coords=da_mean.coords
        )
        #---probability of upper tercile tail
        da_up_tercile_prob = 1 - xr.DataArray(
            da_dist.cdf(ds_tercile_binned['f_midhigh']),
            dims=da_mean.dims,
            coords=da_mean.coords
        )
        #---probability of between lower and upper tercile
        da_mid_tercile_prob = 1 - da_up_tercile_prob - da_low_tercile_prob

        da_tercile_prob = xr.concat(
            [da_low_tercile_prob,da_mid_tercile_prob,da_up_tercile_prob],
            pd.Index([-1,0,1],name="tercile")
        )

        # lower tercile max => negative
        # nomral tercile max => 0
        # upper tercile max => positive
        da_tercile_prob_max = (
            da_tercile_prob.idxmax(dim='tercile',fill_value=np.nan)*
            da_tercile_prob.max(dim='tercile')
        )

        # create dataset to store the tercile calculation
        ds_tercile_prob=xr.Dataset()
        ds_tercile_prob['tercile_prob'] = da_tercile_prob
        ds_tercile_prob['tercile_prob_max'] = da_tercile_prob_max

        return ds_tercile_prob

    def calculate_regional_tercile_prob(
        self,
        lead_bins : List[int] = None,
        region_name : RegionalOptions = 'MAB'
    ) -> xr.Dataset:
        """
        Based on regional averaged value of forecast/hindcast,
        use single initialization's normal distribution
        and pre-defined tercile value based on the long-term
        statistic tercile value to find the probability of
        upper ,normal , and lower tercile

        It also find the largest probability in upper (positive),
        normal (0), lower (negative)

        Parameters
        ----------
        lead_bins : List[int]
            The `lead_bin` used to binned the leading month result
            ex: one can set `lead_bins = [0, 3, 6, 9, 12]` for four seasonal
            mean. Default is no binning, lead_bins = None.

        region_name : ({'MAB','GOM','SS','GB','SS_LME',
                        'NEUS_LME','SEUS_LME','GOMEX','GSL','NGOMEX',
                        'SGOMEX','Antilles','Floridian'), default: "MAB"
            String indicating the regional abbreviation one want to perform
            the regional averaged tercile calculation.


        Returns
        -------
        xr.Dataset
            two variables are in the dataset. (1) tercile_prob
            (2) tercile_prob_max.

            1 is a 2D matrix with the dimension
            of lead x 3. This are the probability of
            upper(lead), normal(lead), and lower tercile(lead)

            2 is the 1D array of largest probability in upper (positive),
            normal (0), lower (negative) with dimension of (lead)
        """

class MOM6Historical:
    """
    Class for various mom6 historical run related calculation
    - get the mom6 files

    """
    def __init__(
        self,
        var : str,
        year : int,
        month : int,
        day : int = 1,
        grid : ModelGridTypeOptions = 'raw',
        source : DataSourceOptions = 'local'
    ) -> None:
        """
        input for getting the historical run data

        Parameters
        ----------
        var : str
            variable name one want to exetract from the data
        year : int
            year of historical run
        month : int
            month of the historical run
        day : int
            day in month of the historical run
        grid : Literal[&#39;raw&#39;,&#39;regrid&#39;], optional
            The data extracted should be the regridded result or 
            the original model grid (curvilinear), by default 'raw'
        source : Literal[&#39;local&#39;,&#39;opendap&#39;], optional
            The source where to import the data, by default 'local'

        """
        self.var = var
        self.year = year
        self.month = month
        self.day = day
        self.grid = grid
        self.source = source

    def get_mom6(self) -> xr.Dataset:
        """
        Return the mom6 rawgrid/regridded historical run field
        with the static field combined and setting the
        lon lat related variables to coordinate 

        Returns
        -------
        xr.Dataset
            The Xarray Dataset object is the merged dataset of
            all forecast field include in the `file_list`. The
            Dataset object is lazily-loaded.
        """
        if self.grid == 'raw' :
            if self.source == 'local':
                # getting the forecast/hindcast data
                mom6_dir = os.path.join(DATA_PATH,"hist_run/")
                file_list = MOM6Misc.mom6_historical(mom6_dir)
                # static field
                ds_static = MOM6Static.get_mom6_grid()
            elif self.source == 'opendap':
                file_list = OpenDapStore(grid=self.grid,data_type='historical').get_catalog()
                for file in file_list:
                    var_flag = 'static' in file
                    if var_flag :
                        ds_static = xr.open_dataset(file)

            # merge the static field with the variables
            for file in file_list:
                var_flag = self.var in file
                if var_flag :
                    ds = xr.open_dataset(file).sel(time=f'{self.year}-{self.month}').compute()

            ds = xr.merge([ds_static,ds])
            # remove the first time index 1980 exist after merging with static field
            ds = ds.sel(time=f'{self.year}-{self.month}')

        elif self.grid == 'regrid':
            if self.source == 'local':
                # getting the forecast/hindcast data
                mom6_dir = os.path.join(DATA_PATH,"hist_run/regrid/")
                file_list = MOM6Misc.mom6_historical(mom6_dir)
            elif self.source == 'opendap':
                file_list = OpenDapStore(grid=self.grid,data_type='historical').get_catalog()

            # read only the needed file
            for file in file_list:
                var_flag = self.var in file
                if var_flag :
                    ds = xr.open_dataset(file).sel(time=f'{self.year}-{self.month}').compute()

        return ds

    @staticmethod
    def get_mom6_all(
        var : str,
        grid : ModelGridTypeOptions = 'raw',
        source : DataSourceOptions = 'local'
    ) -> xr.Dataset:
        """
        Return the mom6 all rawgrid/regridded historical run field
        with the static field combined and setting the
        lon lat related variables to coordinate 

        Parameters
        ----------
        var : str
            variable name one want to exetract from the data
        grid : Literal[&#39;raw&#39;,&#39;regrid&#39;], optional
            The data extracted should be the regridded result or 
            the original model grid (curvilinear), by default 'raw'
        source : Literal[&#39;local&#39;,&#39;opendap&#39;], optional
            The source where to import the data, by default 'local'

        Returns
        -------
        xr.Dataset
            The Xarray Dataset object is the merged dataset of
            all forecast field include in the `file_list`. The
            Dataset object is lazily-loaded.
        """
        if grid == 'raw' :
            if source == 'local':
                # getting the historical run data
                mom6_dir = os.path.join(DATA_PATH,"hist_run/")
                file_list = MOM6Misc.mom6_historical(mom6_dir)
                # static field
                ds_static = MOM6Static.get_mom6_grid()
            elif source == 'opendap':
                file_list = OpenDapStore(grid=grid,data_type='historical').get_catalog()
                for file in file_list:
                    var_flag = 'static' in file
                    if var_flag :
                        ds_static = xr.open_dataset(file)

            file_read = [file for file in file_list if var in file]

            # merge the static field with the variables
            ds = xr.open_mfdataset(
                file_read,combine='nested',
                concat_dim='time',
                chunks={'time': 100}
            ).sortby('time')
            ds = xr.merge([ds_static,ds])
            ds = ds.isel(time=slice(1,None))  # exclude the 1980 empty field due to merge

        elif grid == 'regrid':
            if source == 'local':
                # getting the historical run data
                mom6_dir = os.path.join(DATA_PATH,"hist_run/regrid/")
                file_list = MOM6Misc.mom6_historical(mom6_dir)
            elif source == 'opendap':
                file_list = OpenDapStore(grid=grid,data_type='historical').get_catalog()

            file_read = [file for file in file_list if var in file]
            ds = xr.open_mfdataset(
                file_read,
                combine='nested',
                concat_dim='time',
                chunks={'time': 100}
            ).sortby('time')

        return ds

class MOM6Static:
    """
    Class for getting various Static field
    1. regional mask in raw regional mom6 grid
    2. static file for grid information
    ...
    """
    @staticmethod
    def get_mom6_regionl_mask() -> xr.Dataset:
        """return the EPU mask in the original mom6 grid
        """
        ds = xr.open_dataset(os.path.join(DATA_PATH,"masks/region_masks.nc"))
        ds = ds.set_coords(['geolon','geolat'])
        # change the boolean to 1,nan for mask
        for var in list(ds.keys()):
            if var not in ['areacello', 'geolat', 'geolon']:
                ds[var] = xr.where(ds[var],1.,np.nan)

        return ds

    @staticmethod
    def get_mom6_grid() -> xr.Dataset:
        """return the original mom6 grid information
        """
        ds_static = xr.open_dataset(os.path.join(DATA_PATH,'ocean_static.nc'))
        return ds_static.set_coords(
            ['geolon','geolat',
            'geolon_c','geolat_c',
            'geolon_u','geolat_u',
            'geolon_v','geolat_v']
        )
    @staticmethod
    def get_mom6_mask(
        mask : Literal['wet','wet_c','wet_u','wet_v'] = 'wet',
        grid : ModelGridTypeOptions = 'raw'
    ) -> xr.DataArray:
        """
        The function is designed to export the various mask provided
        on the MOM6 grid from the ocean_static.nc file

        Parameters
        ----------
        mask : str
            The mask name based on the variable name in the ocean_static.nc file.
            It has the following options 1. wet (0 if land, 1 if ocean at
            tracer points), 2. wet_c (0 if land, 1 if ocean at corner (Bu)
            points), 3. wet_u (0 if land, 1 if ocean at zonal velocity (Cu) 
            points), 4. wet_v (0 if land, 1 if ocean at meridional velocity
            (Cv) points), by default 'wet'.
        
        grid : Literal[&#39;raw&#39;,&#39;regrid&#39;], optional
            The data extracted should be the regridded result or 
            the original model grid (curvilinear), by default 'raw'

        Returns
        -------
        xr.DataArray
            The Xarray DataArray object that represent the ocean mask.
        """
        if grid == 'raw':
            ds = xr.open_dataset(os.path.join(DATA_PATH,'static/ocean_static.nc'))
            da = ds.set_coords(['geolon','geolat'])[mask]
        elif grid == 'regrid':
            ds = xr.open_dataset(os.path.join(DATA_PATH,'static/regrid/ocean_static.wet.nc'))
            da = ds[mask]
        return da


class MOM6Misc:
    """MOM6 related methods 
    """
    @staticmethod
    def mom6_historical(
        historical_dir : str
    ) -> List[str]:
        """
        Create list of files to be able to be opened 
        by Xarray.

        Parameters
        ----------
        historical_dir : str
            directory path in string to the historical run

        Returns
        -------
        List 
            A list of all data name including directory path 
            for the historical run data
        """

        # h point list
        hpoint_file_list = [
            "ocean_monthly.199301-201912.MLD_003.nc",
            "ocean_monthly.199301-201912.sos.nc",
            "ocean_monthly.199301-201912.ssh.nc",
            "ocean_monthly.199301-201912.tob.nc",
            "ocean_monthly.199301-201912.tos.nc",
            "ocean_monthly_z.199301-201912.so.nc",
            "ocean_monthly_z.199301-201912.thetao.nc",
            "ocean_cobalt_daily_2d.19930101-20191231.btm_o2.nc",
            "ocean_cobalt_omip_sfc.199301-201912.chlos.nc",
            "ocean_cobalt_omip_sfc.199301-201912.dissicos.nc",
            "ocean_cobalt_omip_sfc.199301-201912.talkos.nc",
            "ocean_cobalt_sfc.199301-201912.sfc_co3_ion.nc",
            "ocean_cobalt_sfc.199301-201912.sfc_co3_sol_arag.nc",
            "ocean_cobalt_sfc.199301-201912.sfc_no3.nc",
            "ocean_cobalt_sfc.199301-201912.sfc_po4.nc",
            "ocean_cobalt_tracers_int.199301-201912.mesozoo_200.nc"
        ]
        hpoint_file_list = [f"{historical_dir}{file}" for file in hpoint_file_list]

        # T point that is the same as h point
        tpoint_file_list = [
            "ice_monthly.199301-201912.siconc.nc"
        ]
        tpoint_file_list = [f"{historical_dir}{file}" for file in tpoint_file_list]

        all_file_list = hpoint_file_list+tpoint_file_list

        return all_file_list

    @staticmethod
    def mom6_hindcast(
        hindcast_dir : str
    ) -> List[str]:
        """
        Create list of files to be able to be opened 
        by Xarray.

        Parameters
        ----------
        hindcast_dir : str
            directory path in string to the forecast/hindcast

        Returns
        -------
        List 
            A list of all data name including directory path 
            for the hindcast/forecast data
           
        """
        # # input of array of different variable forecast
        # tob_files = [f"tob_forecasts_i{mon}.nc" for mon in range(3,13,3)]
        # tos_files = [f"tos_forecasts_i{mon}.nc" for mon in range(3,13,3)]

        # # h point list
        # hpoint_file_list = (
        #     tob_files+
        #     tos_files
        # )

        # hpoint_file_list = [f"{hindcast_dir}{file}" for file in hpoint_file_list]

        # all_file_list = hpoint_file_list

        all_file_list = glob.glob(f'{hindcast_dir}/*.nc')

        return all_file_list

    @staticmethod
    def mom6_encoding_attr(
        ds_data_ori : xr.Dataset,
        ds_data : xr.Dataset,
        dataset_name : str,
        var_names : List[str] = None
    ):
        """
        This function is designed for creating attribute and netCDF encoding
        for the preprocessed regional mom6 file format.

        Parameters
        ----------
        ds_data_ori : xr.Dataset
            original dataset
        ds_data : xr.Dataset
            new output regridded dataset
        var_name : string
            var name in the dataset
        dataset : string
            name of the dataset 

        Returns
        -------
        ds_data : xr.Dataset
            new output regridded dataset with attr and encoding setup.
        
        Raises
        ------

        """

        # besides lon lat which has PSL format
        #  put all dim name that may encounter in
        #  different mom6 output. These dims will
        #  follow its original data attr and encoding
        misc_dims_list = ['time','lead','init','member','z_l']

        if var_names is None:
            var_names = []

        # global attrs and encoding
        ds_data.attrs = ds_data_ori.attrs
        ds_data.encoding = ds_data_ori.encoding
        ds_data.attrs['history'] = "Derived and written at NOAA Physical Science Laboratory"
        ds_data.attrs['contact'] = "chia-wei.hsu@noaa.gov"
        ds_data.attrs['dataset'] = dataset_name

        try:
            # lon and lat attrs and encoding (PSL format)
            # longitude attrs
            ds_data['lon'].attrs = {
                'standard_name' : 'longitude',
                'long_name' : 'longitude',
                'units' : 'degrees_east',
                'axis' : 'X',
                'actual_range' : (
                    np.float64(ds_data['lon'].min()),
                    np.float64(ds_data['lon'].max())
                )
            }
            ds_data['lon'].encoding = {
                'zlib': True,
                'szip': False,
                'zstd': False,
                'bzip2': False,
                'blosc': False,
                'shuffle': True,
                'complevel': 2,
                'fletcher32': False,
                'contiguous': False,
                'chunksizes': [len(ds_data['lon'].data)],
                'original_shape': [len(ds_data['lon'].data)],
                'dtype': 'float64'}
        except KeyError:
            print('no lon dimension')

        try:
            # latitude attrs
            ds_data['lat'].attrs = {
                'standard_name' : 'latitude',
                'long_name' : 'latitude',
                'units' : 'degrees_north',
                'axis' : 'Y',
                'actual_range' : (
                    np.float64(ds_data['lat'].min()),
                    np.float64(ds_data['lat'].max())
                )
            }
            ds_data['lat'].encoding = {
                'zlib': True,
                'szip': False,
                'zstd': False,
                'bzip2': False,
                'blosc': False,
                'shuffle': True,
                'complevel': 2,
                'fletcher32': False,
                'contiguous': False,
                'chunksizes': [len(ds_data['lon'].data)],
                'original_shape': [len(ds_data['lon'].data)],
                'dtype': 'float64'}
        except KeyError:
            print('no lat dimension')

        # copy original attrs and encoding for dims
        for dim in misc_dims_list:
            try:
                ds_data[dim].attrs = ds_data_ori[dim].attrs
                ds_data[dim].encoding = ds_data_ori[dim].encoding
                ds_data[dim].encoding['complevel'] = 2
            except KeyError:
                print(f'no {dim} dimension')

        # copy original attrs and encoding for variables
        for var_name in var_names:
            try:
                ds_data[var_name].attrs = ds_data_ori[var_name].attrs
                ds_data[var_name].encoding = ds_data_ori[var_name].encoding
            except KeyError:
                print(f'new variable name {var_name}')
                ds_data[var_name].encoding['complevel'] = 2

        return ds_data
