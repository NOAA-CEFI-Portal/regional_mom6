"""
The script do a batch reorganiztion of the yearly files
that is generated by Jessie and convert them to single
varible files with the entire time period
"""
import os
import gc
import logging
from glob import glob
import xarray as xr
import shutil

def setup_logging(logfile):
    """Set up logging to write messages to a log file."""
    logging.basicConfig(
        filename=logfile,
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
    )

if __name__ == "__main__":

    # setup logging
    log_filename = 'batch_nep_v2_to_v3_convertion_no2024.log'
    if os.path.exists(log_filename):
        os.remove(log_filename)

    setup_logging(log_filename)

    # original data path
    ORI_PATHS = [
        "/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/daily/raw/r20250509",
        "/Projects/CEFI/regional_mom6/cefi_portal/northeast_pacific/full_domain/hindcast/monthly/raw/r20250509"
    ]

    # output data path
    OUT_PATH = '/Projects/CEFI/private/scratch/chsu/NEP_hindcast_v3'

    # initial year
    initial_year = 1993
    final_year = 2023

    for ori_path in ORI_PATHS:
        logging.info(f'------- Starting processing for: {ori_path} -------')
        # get all the file list from the original path
        ori_files = glob(os.path.join(ori_path, '*.nc'))
        # sort the files by name
        ori_files = sorted(ori_files)

        # lazy load all the original yearly files
        for file in ori_files:
            logging.info(f'Processing file: {file}')
            filename = os.path.basename(file)

            # skip static files
            if "static" in filename:
                # copy the file directly
                OUT_FILE = os.path.join(OUT_PATH, filename)
                shutil.copy2(file, OUT_FILE)
                logging.info(f'Copied static file to -> {OUT_FILE}')
                continue 
            
            # lazy load the dataset
            ds_ori = xr.open_dataset(file, chunks="auto", decode_timedelta=True)
            new_filename = ds_ori.attrs['cefi_ori_filename']

            if ori_path.split('/')[-3] == 'daily':
                # Replace 20241231 with 20231231 in the filename for daily
                new_filename = new_filename.replace('20241231', '20231231')
            elif ori_path.split('/')[-3] == 'monthly':
                # Replace 202412 with 202312 in the filename for monthly
                new_filename = new_filename.replace('202412', '202312')
            else:
                logging.error(f'Unknown time frequency for {ori_path}')

            # based on Liz's suggestion to use only till end of 2023
            ds_ori = ds_ori.sel(time=slice(f'{initial_year}-01-01', f'{final_year}-12-31'))

            # get the output file path and filename
            OUT_FILE = os.path.join(OUT_PATH, new_filename)

            # check if file exist
            if not os.path.exists(OUT_FILE):
                ds_out = ds_ori.compute()
                ds_out.to_netcdf(
                    OUT_FILE,
                    mode='w',
                    format='NETCDF4',
                    unlimited_dims='time'
                )
                del ds_out
                gc.collect()
                logging.info(f'output to -> {OUT_FILE}')
            else :
                logging.warning(f'File {OUT_FILE} already exists. Skipping write.')

        # close the dataset
        ds_ori.close()
        logging.info('All variables converted successfully.')
        logging.info(f'Output files are saved in {OUT_PATH}')
        logging.info(f'Initial year: {initial_year}, Final year: {final_year}')
